{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pickle\n",
    "#import keras\n",
    "\n",
    "from sklearn import svm\n",
    "import random\n",
    "import os\n",
    "from math import floor\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to train the model by yourself\n",
    "\n",
    "# train data\n",
    "with open('train_data.pickle', 'rb') as f:\n",
    "    Data = pickle.load(f)\n",
    "    Data = pd.DataFrame(Data)\n",
    "\n",
    "numtrain = 1012 * 6 * 12\n",
    "numval = int(numtrain * 0.2)\n",
    "\n",
    "\n",
    "# Train validation split\n",
    "idx = random.sample(range(numtrain), numval) # 80% for training\n",
    "all_index = list(np.setdiff1d(range(numtrain), idx))\n",
    "\n",
    "# Getting X_train, X_val, y_train and scale them\n",
    "\n",
    "X_train = Data.iloc[all_index,:].drop(2251, axis = 1)\n",
    "X_val = Data.iloc[idx,:].drop(2251, axis = 1)\n",
    "y_train = pd.get_dummies(Data.iloc[all_index,:][2251])\n",
    "#print(y_train)\n",
    "\n",
    "names = y_train.columns\n",
    "mapping = {}\n",
    "i = 0\n",
    "for n in names:\n",
    "    mapping[i] = n\n",
    "    i+=1\n",
    "#print(mapping)\n",
    "\n",
    "y_train = Data.iloc[all_index,:][2251]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.read_csv('test_data_30.csv')\n",
    "Test_filter = Test.fillna(method='ffill')\n",
    "\n",
    "X_test = scaler.transform(Test_filter.iloc[:,1:])\n",
    "#pred = clf.predict(X_test)\n",
    "\n",
    "probas = model.predict_proba(X_test)\n",
    "top_n_predictions = np.argsort(probas, axis = 1)[:,-11:]\n",
    "\n",
    "result = []\n",
    "for pre in top_n_predictions:\n",
    "    pre_list = []\n",
    "    for index in pre:\n",
    "        pre_list.append(mapping[index])\n",
    "    result.append(pre_list)\n",
    "\n",
    "    \n",
    "for plist in result:\n",
    "    plist.reverse()\n",
    "    print(plist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MAXFIA', 'MOF-5', 'XAYMUF', 'REHRIH', 'JARMEU10', 'QIJLAW', 'RARBES', 'JARMEU', 'COMXUZ', 'ZIF-11', 'FOHJAP']\n",
      "['MAXFIA', 'MOF-5', 'XAYMUF', 'REHRIH', 'QIJLAW', 'RARBES', 'JARMEU', 'COMXUZ', 'JARMEU10', 'ZIF-11', 'FOHJAP']\n",
      "['MAXFIA', 'JARMEU10', 'MOF-5', 'XAYMUF', 'REHRIH', 'QIJLAW', 'RARBES', 'JARMEU', 'ZIF-11', 'FOHJAP', 'COMXUZ']\n",
      "['REHRIH', 'JARMEU', 'JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'ZIF-73', 'REJPIH', 'GEPYIK', 'XANLUV', 'LIKRAZ']\n",
      "['XAYMUF', 'REHRIH', 'JARMEU', 'JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'ZIF-73', 'REJPIH', 'GEPYIK', 'LIKRAZ']\n",
      "['MOF-5', 'XAYMUF', 'REHRIH', 'JARMEU', 'JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'ZIF-73', 'GEPYIK', 'REJPIH']\n",
      "['REHRIH', 'JARMEU', 'JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'XAYMUF', 'DUT-23', 'FUDGOC', 'PIZJEN', 'TEWMIS']\n",
      "['JARMEU', 'JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'XAYMUF', 'ZIF-90', 'DUT-23', 'FUDGOC', 'PIZJEN', 'TEWMIS']\n",
      "['REHRIH', 'JARMEU', 'JARMEU10', 'QIJLAW', 'RARBES', 'COMXUZ', 'XAYMUF', 'DUT-23', 'FUDGOC', 'PIZJEN', 'TEWMIS']\n",
      "['MOF-5', 'XAYMUF', 'REHRIH', 'JARMEU', 'JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'DUT-23', 'FUDGOC', 'PIZJEN']\n",
      "['JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'XAYMUF', 'ZIF-90', 'DUT-23', 'FUDGOC', 'PIZJEN', 'MESTOU', 'TEWMIS']\n",
      "['MOF-5', 'XAYMUF', 'REHRIH', 'JARMEU', 'JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'DUT-23', 'FUDGOC', 'PIZJEN']\n",
      "['XAYMUF', 'REHRIH', 'JARMEU10', 'QIJLAW', 'RARBES', 'COMXUZ', 'JARMEU', 'BEWCUD', 'ZIF-77', 'ZIF-11', 'FOHJAP']\n",
      "['NODTIL', 'MAXFIA', 'MOF-5', 'XAYMUF', 'REHRIH', 'JARMEU10', 'QIJLAW', 'RARBES', 'COMXUZ', 'JARMEU', 'FOHJAP']\n",
      "['MOF-5', 'XAYMUF', 'REHRIH', 'JARMEU', 'JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'BEWCUD', 'ZIF-11', 'FOHJAP']\n",
      "['MAXFIA', 'MOF-5', 'XAYMUF', 'REHRIH', 'JARMEU', 'JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'FALJEJ', 'YODTAN']\n",
      "['MAXFIA', 'MOF-5', 'XAYMUF', 'REHRIH', 'JARMEU', 'JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'PAZSOZ', 'FALJEJ']\n",
      "['REHRIH', 'JARMEU', 'JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'PAZSOZ', 'UGUXAV', 'FALJEJ', 'YODTAN', 'UCOQEK']\n",
      "['JOSNAG01', 'JOSNAG', 'JOKYOX10', 'JOKYOX', 'JOKYIR10', 'JOKYIR', 'JOKYEN10', 'JOKYEN', 'JOKYAJ10', 'HUYKIV', 'ZUYWAR']\n",
      "['JOSNAG01', 'JOSNAG', 'JOKYOX10', 'JOKYOX', 'JOKYIR10', 'JOKYIR', 'JOKYEN10', 'JOKYEN', 'JOKYAJ10', 'HUYKIV', 'ZUYWAR']\n",
      "['JOSNAG01', 'JOSNAG', 'JOKYOX10', 'JOKYOX', 'JOKYIR10', 'JOKYIR', 'JOKYEN10', 'JOKYEN', 'JOKYAJ10', 'HUYKIV', 'ZUYWAR']\n",
      "['MAXFIA', 'MOF-5', 'XAYMUF', 'REHRIH', 'JARMEU', 'JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'QAYTOZ', 'OYOSUR']\n",
      "['XAYMUF', 'REHRIH', 'JARMEU', 'JARMEU10', 'COMXUZ', 'QIJLAW', 'RARBES', 'ZECKOJ', 'ZEDGEW', 'MIBQAR19', 'KOPHOO']\n",
      "['JOSNAG01', 'JOSNAG', 'JOKYOX10', 'JOKYOX', 'JOKYIR10', 'JOKYIR', 'JOKYEN10', 'JOKYEN', 'JOKYAJ10', 'HUYKIV', 'ZUYWAR']\n"
     ]
    }
   ],
   "source": [
    "top_n_predictions = np.argsort(probas, axis = 1)[:,-5:]\n",
    "\n",
    "result = []\n",
    "for pre in top_n_predictions:\n",
    "    pre_list = []\n",
    "    for index in pre:\n",
    "        pre_list.append(mapping[index])\n",
    "    result.append(pre_list)\n",
    "\n",
    "    \n",
    "for plist in result:\n",
    "    plist.reverse()\n",
    "    print(plist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):    \n",
    "    top_n_predictions = np.argsort(probas, axis = 1)[:,-i:]\n",
    "\n",
    "    result = []\n",
    "    for pre in top_n_predictions:\n",
    "        pre_list = []\n",
    "        for index in pre:\n",
    "            pre_list.append(mapping[index])\n",
    "        result.append(pre_list)\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    for p in result[:3]:\n",
    "        if 'ZIF-67' in p:\n",
    "            count += 1\n",
    "    for p in result[3:6]:\n",
    "        if 'ZIF-71' in p:\n",
    "            count += 1\n",
    "    for p in result[6:9]:\n",
    "        if 'ZIF-8' in p:\n",
    "            count += 1\n",
    "    for p in result[9:12]:\n",
    "        if 'ZIF-90' in p:\n",
    "            count += 1\n",
    "    for p in result[12:15]:\n",
    "        if 'ZIF-7' in p:\n",
    "            count += 1\n",
    "    for p in result[15:18]:\n",
    "        if 'ZIF-9' in p:\n",
    "            count += 1\n",
    "    for p in result[18:21]:\n",
    "        if 'MOF-5' in p:\n",
    "            count += 1\n",
    "    for p in result[21:24]:\n",
    "        if 'MOF-74' in p:\n",
    "            count += 1\n",
    "    for p in result[24:27]:\n",
    "        if 'MOF-199' in p:\n",
    "            count += 1\n",
    "    for p in result[27:30]:\n",
    "        if 'MOF-2' in p:\n",
    "            count += 1\n",
    "\n",
    "    accuracy = count/30\n",
    "    print('top' + str(i) + ' ' + 'accuracy:' +str(accuracy))\n",
    "    print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
